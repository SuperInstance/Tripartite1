{
  "name": "standard",
  "description": "Standard profile for systems with 16GB RAM and entry-level GPU (4GB VRAM)",
  "min_requirements": {
    "ram_bytes": 17179869184,
    "vram_bytes": 4294967296,
    "disk_bytes": 21474836480
  },
  "recommendations": {
    "pathos": {
      "model": "phi-3-mini",
      "quantization": "q4_k_m",
      "repo_id": "microsoft/Phi-3-mini-4k-instruct-gguf",
      "filename": "Phi-3-mini-4k-instruct-q4.gguf",
      "size_bytes": 2200000000,
      "sha256": null,
      "context_size": 4096
    },
    "logos": {
      "model": "llama-3.2-8b",
      "quantization": "q4_k_m",
      "repo_id": "bartowski/Meta-Llama-3.2-8B-Instruct-GGUF",
      "filename": "Meta-Llama-3.2-8B-Instruct-Q4_K_M.gguf",
      "size_bytes": 4700000000,
      "sha256": null,
      "context_size": 8192
    },
    "ethos": {
      "model": "mistral-7b-instruct",
      "quantization": "q4_k_m",
      "repo_id": "TheBloke/Mistral-7B-Instruct-v0.2-GGUF",
      "filename": "mistral-7b-instruct-v0.2.Q4_K_M.gguf",
      "size_bytes": 4100000000,
      "sha256": null,
      "context_size": 8192
    },
    "embeddings": {
      "model": "bge-small-en-v1.5",
      "repo_id": "BAAI/bge-small-en-v1.5",
      "filename": "model.safetensors",
      "size_bytes": 130000000,
      "dimensions": 384
    }
  },
  "inference": {
    "gpu_layers": 20,
    "context_size": 4096,
    "batch_size": 512
  },
  "total_download_size": 11130000000,
  "estimated_vram_usage": 3500000000
}
